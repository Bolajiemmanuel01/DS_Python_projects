{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CW2: Natural Language Processing: Classification of News Articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import neccesary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import (\n",
    "    TextVectorization,\n",
    "    Embedding,\n",
    "    LSTM,\n",
    "    Bidirectional,\n",
    "    Dense,\n",
    "    Embedding,\n",
    ")\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data preparation\n",
    "Import dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title   \n",
       "0            3  Wall St. Bears Claw Back Into the Black (Reuters)  \\\n",
       "1            3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset. As done in lab 4, you usually have a look at the data. Here we simply show the first 5 rows\n",
    "train_data = pd.read_csv(\"news_dataset/train.csv\")\n",
    "test_data = pd.read_csv(\"news_dataset/test.csv\")\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n"
     ]
    }
   ],
   "source": [
    "# Here shows what the news looks like\n",
    "print(train_data[\"Description\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119990</th>\n",
       "      <td>1</td>\n",
       "      <td>Barack Obama Gets  #36;1.9 Million Book Deal (AP)</td>\n",
       "      <td>AP - U.S. Sen.-elect Barack Obama, whose 1995 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119991</th>\n",
       "      <td>2</td>\n",
       "      <td>Rauffer Beats Favorites to Win Downhill</td>\n",
       "      <td>VAL GARDENA, Italy (Reuters) - Max Rauffer be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119992</th>\n",
       "      <td>1</td>\n",
       "      <td>Iraqis Face Winter Shivering by Candlelight</td>\n",
       "      <td>BAGHDAD (Reuters) - As if the daily struggle ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119993</th>\n",
       "      <td>1</td>\n",
       "      <td>AU Says Sudan Begins Troop Withdrawal from Darfur</td>\n",
       "      <td>ABUJA (Reuters) - The African Union said on S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119994</th>\n",
       "      <td>1</td>\n",
       "      <td>Syria Redeploys Some Security Forces in Lebanon</td>\n",
       "      <td>BEIRUT (Reuters) - Syria, under intense press...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119995</th>\n",
       "      <td>1</td>\n",
       "      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n",
       "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119996</th>\n",
       "      <td>2</td>\n",
       "      <td>Renteria signing a top-shelf deal</td>\n",
       "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119997</th>\n",
       "      <td>2</td>\n",
       "      <td>Saban not going to Dolphins yet</td>\n",
       "      <td>The Miami Dolphins will put their courtship of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119998</th>\n",
       "      <td>2</td>\n",
       "      <td>Today's NFL games</td>\n",
       "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119999</th>\n",
       "      <td>2</td>\n",
       "      <td>Nets get Carter from Raptors</td>\n",
       "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Class Index                                              Title   \n",
       "119990            1  Barack Obama Gets  #36;1.9 Million Book Deal (AP)  \\\n",
       "119991            2            Rauffer Beats Favorites to Win Downhill   \n",
       "119992            1        Iraqis Face Winter Shivering by Candlelight   \n",
       "119993            1  AU Says Sudan Begins Troop Withdrawal from Darfur   \n",
       "119994            1    Syria Redeploys Some Security Forces in Lebanon   \n",
       "119995            1  Pakistan's Musharraf Says Won't Quit as Army C...   \n",
       "119996            2                  Renteria signing a top-shelf deal   \n",
       "119997            2                    Saban not going to Dolphins yet   \n",
       "119998            2                                  Today's NFL games   \n",
       "119999            2                       Nets get Carter from Raptors   \n",
       "\n",
       "                                              Description  \n",
       "119990  AP - U.S. Sen.-elect Barack Obama, whose 1995 ...  \n",
       "119991   VAL GARDENA, Italy (Reuters) - Max Rauffer be...  \n",
       "119992   BAGHDAD (Reuters) - As if the daily struggle ...  \n",
       "119993   ABUJA (Reuters) - The African Union said on S...  \n",
       "119994   BEIRUT (Reuters) - Syria, under intense press...  \n",
       "119995   KARACHI (Reuters) - Pakistani President Perve...  \n",
       "119996  Red Sox general manager Theo Epstein acknowled...  \n",
       "119997  The Miami Dolphins will put their courtship of...  \n",
       "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...  \n",
       "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the end of the dataset\n",
    "train_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120000, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120000 entries, 0 to 119999\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Class Index  120000 non-null  int64 \n",
      " 1   Title        120000 non-null  object\n",
      " 2   Description  120000 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 2.7+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>120000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.118039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Class Index\n",
       "count  120000.000000\n",
       "mean        2.500000\n",
       "std         1.118039\n",
       "min         1.000000\n",
       "25%         1.750000\n",
       "50%         2.500000\n",
       "75%         3.250000\n",
       "max         4.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_data.shape)  # To check the number of rows and columns\n",
    "train_data.info()  # To understand data types and non-null counts\n",
    "train_data.describe()  # To get statistical information about numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change labels from 1-4 to 0-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substract 1 from the target variable for both, train and test data\n",
    "train_data[\"Class Index\"] = train_data[\"Class Index\"] - 1\n",
    "test_data[\"Class Index\"] = test_data[\"Class Index\"] - 1\n",
    "label_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"] # 0 is \"World\", 1 is \"Sports\", ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title   \n",
       "0            2  Wall St. Bears Claw Back Into the Black (Reuters)  \\\n",
       "1            2  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            2  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            2  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if t has been corrected\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "\n",
    "Lowercase descriptions and clean up non-letter characters.\n",
    "\n",
    "**TODO 1**: Remove the occurences of \"http\" \"href\", \"https\" and \"www\". Also, remove the names of the news agencies (Reuters, AP, ...) from the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class Index</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>short sellers  wall street s dwindling band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>private investment firm carlyle group  whic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>soaring crude prices plus worries about the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>authorities have halted oil export flows fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>tearaway world oil prices  toppling records...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class Index                                              Title   \n",
       "0            2  Wall St. Bears Claw Back Into the Black (Reuters)  \\\n",
       "1            2  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2            2    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3            2  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4            2  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                         Description  \n",
       "0     short sellers  wall street s dwindling band...  \n",
       "1     private investment firm carlyle group  whic...  \n",
       "2     soaring crude prices plus worries about the...  \n",
       "3     authorities have halted oil export flows fr...  \n",
       "4     tearaway world oil prices  toppling records...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to preprocess the data\n",
    "def preprocess_text(string):\n",
    "    # Remove http, https, href, and www\n",
    "    string = re.sub(r\"\\b(?:http|https|href|www)\\S*\\b\", \"\", string)\n",
    "\n",
    "    # Remove news agencies names\n",
    "    news_agencies = [\"Reuters\", \"AFP\", \"AP\"]  # nList of news agencies\n",
    "    for agency in news_agencies:\n",
    "        string = re.sub(r'\\b' + agency + r'\\b', '', string, flags=re.IGNORECASE)\n",
    "\n",
    "    string = string.lower()\n",
    "    string = string.replace(\"'\", \" \")\n",
    "    string = string.replace(\"\\\\\", \" \")\n",
    "    string = re.sub(r\"[^a-zA-Z]\", \" \", string)\n",
    "    return string\n",
    "\n",
    "# Apply the preprocessing function to the 'Description' column in both train and test datasets\n",
    "train_data[\"Description\"] = train_data[\"Description\"].apply(preprocess_text)\n",
    "test_data[\"Description\"] = test_data[\"Description\"].apply(preprocess_text)\n",
    "\n",
    "\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframes to lists (needed for further functions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframes to list\n",
    "train_data_list = train_data[\"Description\"].tolist()\n",
    "test_data_list = test_data[\"Description\"].tolist()\n",
    "train_labels_list = train_data[\"Class Index\"].tolist()\n",
    "test_labels_list = test_data[\"Class Index\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create validation set (taking out 20% of test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data_list, validation_data_list,\n",
    " train_labels_list, validation_labels_list) = train_test_split(train_data_list, train_labels_list, test_size=0.2, stratify=train_labels_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Stop Words\n",
    "Remove stopwords from the *stopword* corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\a\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "# Create the function to remove stopwords\n",
    "def remove_stopwords(data_list):\n",
    "    stopword_list = stopwords.words(\"english\")\n",
    "    for i in range(len(data_list)):\n",
    "        data_list[i] = \" \".join(\n",
    "            [word for word in data_list[i].split() if word not in (stopword_list)]\n",
    "        )\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_list = remove_stopwords(train_data_list)\n",
    "validation_data_list = remove_stopwords(validation_data_list)\n",
    "test_data_list = remove_stopwords(test_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO 2: STEMMING\n",
    "Use **Stemming** or **Lemmatization** to grammatical word variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\a\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Initialize stemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Function for stemming\n",
    "def perform_stemming(text):\n",
    "    stemmed_text = \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "    return stemmed_text\n",
    "\n",
    "# Apply stemming to the data\n",
    "stemmed_train_data_list = [perform_stemming(text) for text in train_data_list]\n",
    "stemmed_validation_data_list = [perform_stemming(text) for text in validation_data_list]\n",
    "stemmed_test_data_list = [perform_stemming(text) for text in test_data_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recurrent Neural Network classifier with Keras and Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encode the labels (0 -> 0001, 1 -> 0010, ...) to match NN classifier head output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 4)\n"
     ]
    }
   ],
   "source": [
    "# the labels are of value 0, 1, 2, 3. We need to convert them to one-hot encoded vectors \n",
    "train_labels = tensorflow.keras.utils.to_categorical(np.array(train_labels_list), num_classes=4)\n",
    "validation_labels = tensorflow.keras.utils.to_categorical(np.array(validation_labels_list), num_classes=4)\n",
    "test_labels = tensorflow.keras.utils.to_categorical(np.array(test_labels_list), num_classes=4)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we use the TextVectorization layer to convert the text to a sequence of integers. You can read about how this works  [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '[UNK]', 'said', 'new', 'year', 'quot', 'compani', 'two', 'us', 'first', 'lt', 'gt', 'world', 'one', 'monday', 'wednesday', 'tuesday', 'thursday', 'inc', 'friday', 'game', 'week', 'report', 'state', 'u', 'last', 'yesterday', 'york', 'say', 'time', 'presid', 'unit', 'million', 'three', 'nation', 'day', 'price', 'corp', 'stock', 'oil', 'govern', 'plan', 'sunday', 'offici', 'secur', 'would', 'month', 'group', 'servic', 'today', 'peopl', 'announc', 'second', 'open', 'team', 'market', 'could', 'win', 'end', 'season', 'iraq', 'saturday', 'kill', 'percent', 'softwar', 'night', 'next', 'back', 'third', 'use', 'expect', 'busi', 'minist', 'quarter', 'microsoft', 'comput', 'make', 'countri', 'share', 'lead', 'high', 'intern', 'run', 'record', 'internet', 'take', 'network', 'four', 'billion', 'technolog', 'final', 'american', 'help', 'system', 'washington', 'top', 'may', 'elect', 'sale', 'research', 'citi', 'news', 'former', 'leader', 'home', 'releas', 'victori', 'target', 'start', 'feder', 'call', 'manag', 'offer', 'n', 'bank', 'player', 'oper', 'forc', 'attack', 'product', 'giant', 'european', 'gener', 'trade', 'like', 'major', 'set', 'leagu', 'maker', 'move', 'profit', 'get', 'largest', 'industri', 'play', 'show', 'accord', 'base', 'san', 'co', 'five', 'prime', 'point', 'chief', 'execut', 'court', 'bush', 'deal', 'china', 'includ', 'made', 'develop', 'search', 'hit', 'least', 'sport', 'coach', 'face', 'launch', 'agre', 'onlin', 'london', 'long', 'work', 'phone', 'talk', 'olymp', 'seri', 'go', 'british', 'power', 'cup', 'way', 'charg', 'test', 'champion', 'iraqi', 'cut', 'com', 'head', 'sinc', 'polic', 'href', 'old', 'anoth', 'close', 'space', 'south', 'dollar', 'palestinian', 'look', 'offic', 'job', 'john', 'union', 'continu', 'music', 'sign', 'red', 'file', 'web', 'p', 'left', 'hope', 'post', 'come', 'part', 'meet', 'even', 'right', 'provid', 'cost', 'earn', 'mobil', 'increas', 'baghdad', 'rate', 'claim', 'tri', 'rule', 'firm', 'quickinfo', 'fullquot', 'war', 'earli', 'six', 'bid', 'india', 'warn', 'score', 'north', 'militari', 'loss', 'rival', 'bomb', 'al', 'consum', 'drug', 'return', 'mani', 'round', 'follow', 'hold', 'buy', 'demand', 'support', 'give', 'biggest', 'store', 'rose', 'ago', 'man', 'japan', 'still', 'beat', 'strong', 'investor', 'sourc', 'reach', 'line', 'user', 'half', 'retail', 'big', 'program', 'number', 'th', 'googl', 'recent', 'street', 'championship', 'growth', 'latest', 'much', 'higher', 'region', 'wireless', 'australia', 'race', 'agenc', 'sell', 'want', 'held', 'data', 'associ', 'car', 'nuclear', 'air', 'public', 'airlin', 'put', 'isra', 'vote', 'athen', 'rais', 'commun', 'result', 'foreign', 'fire', 'england', 'boston', 'rise', 'found', 'chang', 'custom', 'footbal', 'site', 'pay', 'place', 'turn', 'west', 'remain', 'econom', 'near', 'global', 'allow', 'window', 'name', 'fourth', 'sever', 'issu', 'milit', 'hous', 'financi', 'engin', 'seven', 'effort', 'becom', 'version', 'despit', 'nearli', 'presidenti', 'need', 'fell', 'gold', 'futur', 'free', 'parti', 'fight', 'economi', 'angel', 'ahead', 'ibm', 'press', 'contract', 'took', 'russian', 'past', 'chip', 'amp', 'univers', 'key', 'troop', 'worker', 'francisco', 'also', 'around', 'investig', 'mark', 'america', 'star', 'low', 'defens', 'match', 'hurrican', 'appl', 'gain', 'commiss', 'late', 'lower', 'fund', 'sox', 'wall', 'chicago', 'scientist', 'titl', 'campaign', 'good', 'tokyo', 'video', 'polit', 'keep', 'concern', 'well', 'pc', 'capit', 'europ', 'interest', 'profil', 'order', 'begin', 'septemb', 'possibl', 'australian', 'school', 'member', 'led', 'agreement', 'per', 'miss', 'men', 'octob', 'receiv', 'control', 'rebel', 'hand', 'gaza', 'step', 'field', 'author', 'drop', 'ad', 'st', 'media', 'e', 'accus', 'pass', 'appear', 'design', 'best', 'digit', 'term', 'center', 'depart', 'russia', 'bill', 'build', 'decis', 'fall', 'franc', 'shot', 'corpor', 'devic', 'french', 'aim', 'b', 'confer', 'person', 'hour', 'might', 'battl', 'find', 'server', 'electron', 'oracl', 'eight', 'peac', 'un', 'yard', 'case', 'whether', 'propos', 'death', 'approv', 'invest', 'florida', 'crude', 'produc', 'energi', 'ask', 'northern', 'lo', 'televis', 'reserv', 'hostag', 'japanes', 'inform', 'novemb', 'fan', 'canadian', 'suppli', 'southern', 'rank', 'improv', 'grow', 'creat', 'net', 'life', 'michael', 'club', 'perform', 'board', 'without', 'boost', 'leav', 'yanke', 'britain', 'posit', 'fail', 'told', 'sun', 'due', 'littl', 'see', 'pakistan', 'alleg', 'soldier', 'die', 'away', 'drive', 'mail', 'intel', 'central', 'california', 'secretari', 'terror', 'administr', 'stop', 'morn', 'visit', 'injur', 'account', 'level', 'straight', 'weekend', 'tax', 'challeng', 'applic', 'armi', 'nasa', 'iran', 'goal', 'quarterli', 'lost', 'peoplesoft', 'across', 'analyst', 'action', 'protect', 'medal', 'problem', 'chairman', 'women', 'question', 'live', 'forecast', 'exchang', 'prepar', 'houston', 'food', 'success', 'judg', 'democrat', 'regul', 'push', 'organ', 'israel', 'side', 'linux', 'uk', 'complet', 'ralli', 'insur', 'competit', 'believ', 'arrest', 'strike', 'oct', 'health', 'arm', 'caus', 'area', 'law', 'decid', 'join', 'inning', 'thousand', 'almost', 'critic', 'money', 'studi', 'barrel', 'trial', 'touchdown', 'korea', 'histori', 'attempt', 'doubl', 'small', 'senior', 'aid', 'revenu', 'list', 'human', 'david', 'better', 'basebal', 'kerri', 'size', 'advanc', 'among', 'spend', 'wound', 'font', 'grand', 'threaten', 'defeat', 'emerg', 'stadium', 'earlier', 'ltd', 'bring', 'larg', 'ever', 'divis', 'suspect', 'euro', 'send', 'nov', 'began', 'minut', 'william', 'manufactur', 'east', 'fear', 'behind', 'seek', 'nine', 'toronto', 'fuel', 'texa', 'less', 'cent', 'consid', 'flight', 'anti', 'explos', 'access', 'real', 'popular', 'lawsuit', 'full', 'cash', 'speed', 'got', 'defend', 'break', 'august', 'darfur', 'came', 'toward', 'arafat', 'station', 'initi', 'germani', 'amid', 'link', 'bankruptci', 'privat', 'western', 'indian', 'unveil', 'yet', 'local', 'threat', 'relat', 'clear', 'alreadi', 'afghanistan', 'sept', 'quarterback', 'negoti', 'main', 'current', 'tie', 'carri', 'prison', 'pari', 'featur', 'cell', 'financ', 'declin', 'canada', 'publish', 'extend', 'lose', 'decad', 'career', 'famili', 'weapon', 'stand', 'confirm', 'offens', 'german', 'employe', 'acquir', 'project', 'white', 'import', 'opposit', 'island', 'desktop', 'arsen', 'sudan', 'process', 'chines', 'struggl', 'card', 'pull', 'watch', 'messag', 'hard', 'ban', 'radio', 'insurg', 'bodi', 'injuri', 'far', 'chanc', 'activ', 'georg', 'event', 'violenc', 'storm', 'replac', 'soon', 'director', 'promis', 'gave', 'takeov', 'within', 'muslim', 'african', 'outsid', 'jone', 'tour', 'expand', 'delay', 'appeal', 'jump', 'short', 'save', 'polici', 'ga', 'legal', 'train', 'paul', 'avail', 'stake', 'tech', 'bowl', 'travel', 'standard', 'involv', 'enough', 'met', 'terrorist', 'heart', 'arriv', 'slow', 'finish', 'known', 'let', 'know', 'pressur', 'dead', 'taken', 'other', 'miami', 'yasser', 'hundr', 'urg', 'soni', 'guard', 'green', 'hospit', 'great', 'strip', 'council', 'seattl', 'annual', 'export', 'wide', 'thing', 'manchest', 'bay', 'seem', 'coast', 'beij', 'park', 'worri', 'motor', 'suggest', 'retir', 'figur', 'effect', 'tv', 'host', 'potenti', 'movi', 'holiday', 'africa', 'think', 'moscow', 'schedul', 'must', 'introduc', 'track', 'yahoo', 'reduc', 'enter', 'water', 'practic', 'risk', 'suffer', 'survey', 'stage', 'singl', 'qualifi', 'updat', 'troubl', 'equip', 'enterpris', 'domin', 'went', 'reject', 'cp', 'rang', 'protest', 'toni', 'candid', 'expert', 'blue', 'settl', 'express', 'spain', 'download', 'crash', 'heat', 'rocket', 'town', 'madrid', 'colleg', 'lift', 'labor', 'children', 'owner', 'ipod', 'medic', 'islam', 'damag', 'shop', 'respons', 'atlanta', 'never', 'form', 'italian', 'carrier', 'cite', 'tool', 'surg', 'sent', 'reveal', 'disput', 'processor', 'everi', 'imag', 'pitch', 'nfl', 'cb', 'basketbal', 'color', 'illeg', 'estim', 'jet', 'brown', 'calif', 'loui', 'eu', 'tournament', 'pick', 'resign', 'newspap', 'suspend', 'poll', 'detroit', 'readi', 'ground', 'ceo', 'special', 'ship', 'captain', 'averag', 'tiger', 'machin', 'surpris', 'award', 'land', 'controversi', 'philadelphia', 'fifth', 'eas', 'advertis', 'decemb', 'connect', 'satellit', 'discuss', 'winter', 'sold', 'benefit', 'repres', 'republican', 'partner', 'black', 'stay', 'withdraw', 'nasdaq', 'confid', 'differ', 'deliv', 'worth', 'kidnap', 'plant', 'edg', 'celebr', 'aug', 'suicid', 'book', 'staff', 'sharehold', 'w', 'crisi', 'spokesman', 'plane', 'homer', 'memori', 'later', 'forward', 'block', 'playoff', 'fresh', 'earth', 'cricket', 'camp', 'seen', 'young', 'mike', 'avoid', 'airway', 'accept', 'summer', 'direct', 'though', 'seed', 'mission', 'steve', 'given', 'commerci', 'spam', 'care', 'outlook', 'model', 'asian', 'statement', 'dvd', 'road', 'explor', 'browser', 'winner', 'c', 'purchas', 'light', 'asia', 'singapor', 'total', 'debt', 'check', 'draw', 'spot', 'g', 'brand', 'wait', 'focu', 'senat', 'ivan', 'entertain', 'border', 'abl', 'dozen', 'blair', 'whose', 'afghan', 'middl', 'evid', 'wit', 'crowd', 'attorney', 'fraud', 'word', 'blast', 'airport', 'acquisit', 'thought', 'athlet', 'predict', 'valu', 'soccer', 'serv', 'closer', 'agent', 'safeti', 'pilot', 'electr', 'debat', 'vehicl', 'ireland', 'sharon', 'roll', 'content', 'becam', 'pro', 'minnesota', 'measur', 'januari', 'moon', 'hear', 'dow', 'review', 'juli', 'condit', 'committe', 'along', 'rebound', 'pound', 'limit', 'assist', 'appar', 'greec', 'prize', 'credit', 'voter', 'marin', 'huge', 'storag', 'chain', 'age', 'rain', 'ms', 'interim', 'film', 'congress', 'cours', 'view', 'option', 'settlement', 'mean', 'bond', 'x', 'johnson', 'hotel', 'deficit', 'although', 'suit', 'scandal', 'reason', 'pack', 'eye', 'davi', 'mile', 'fine', 'declar', 'cleric', 'role', 'mw', 'jail', 'golf', 'dell', 'ten', 'rest', 'najaf', 'clash', 'xp', 'lawyer', 'singh', 'pictur', 'zealand', 'woman', 'itali', 'independ', 'highest', 'dutch', 'quit', 'nyse', 'justic', 'hole', 'driver', 'consecut', 'arab', 'ryder', 'jose', 'broadcast', 'disappoint', 'merger', 'eastern', 'tonight', 'mortgag', 'hostil', 'heavi', 'front', 'code', 'nba', 'formula', 'de', 'built', 'brought', 'act', 'virginia', 'scienc', 'rock', 'ministri', 'roger', 'march', 'kept', 'aircraft', 'sector', 'upgrad', 'striker', 'discov', 'ariel', 'verdana', 'serif', 'immedi', 'helvetica', 'detail', 'await', 'arial', 'slightli', 'master', 'mass', 'fix', 'premier', 'dec', 'sharpli', 'captur', 'resid', 'admit', 'platform', 'mine', 'hill', 'saw', 'prevent', 'instead', 'debut', 'suprem', 'photo', 'patent', 'intellig', 'conflict', 'commit', 'promot', 'indic', 'document', 'afternoon', 'tell', 'passeng', 'korean', 'bad', 'wood', 'vice', 'spanish', 'period', 'parliament', 'parent', 'weak', 'inflat', 'diplomat', 'deni', 'asset', 'vendor', 'row', 'oakland', 'fallujah', 'box', 'abus', 'rush', 'pace', 'missil', 'cardin', 'student', 'screen', 'violat', 'streak', 'fli', 'fast', 'stori', 'display', 'previou', 'integr', 'centuri', 'approach', 'victim', 'sprint', 'session', 'probe', 'carolina', 'write', 'refus', 'probabl', 'prix', 'la', 'howard', 'classic', 'walk', 'panel', 'explod', 'dalla', 'ball', 'yuko', 'incom', 'longer', 'cisco', 'resum', 'recal', 'soar', 'signal', 'insist', 'packag', 'kick', 'kabul', 'telephon', 'kong', 'format', 'delta', 'boe', 'worldwid', 'massiv', 'interview', 'insid', 'civil', 'wind', 'tom', 'struck', 'spacecraft', 'sentenc', 'pittsburgh', 'delhi', 'camera', 'viru', 'pitcher', 'joint', 'danger', 'compet', 'chelsea', 'murder', 'king', 'hong', 'employ', 'cleveland', 'weather', 'prosecutor', 'peer', 'distribut', 'threw', 'ran', 'natur', 'tenni', 'poor', 'f', 'doctor', 'crime', 'togeth', 'rout', 'wave', 'sydney', 'cross', 'brazil', 'tim', 'room', 'provinc', 'hurt', 'blow', 'thank', 'requir', 'prove', 'abu', 'reform', 'jerusalem', 'disney', 'command', 'broadband', 'royal', 'ray', 'kansa', 'index', 'astro', 'spent', 'semiconductor', 'mexico', 'hire', 'combin', 'cabl', 'remov', 'own', 'jason', 'feel', 'deploy', 'count', 'climb', 'assault', 'bear', 'anticip', 'add', 'request', 'pension', 'hollywood', 'doubt', 'crimin', 'song', 'read', 'hockey', 'ventur', 'institut', 'eagl', 'capabl', 'broke', 'studio', 'someth', 'planet', 'learn', 'cover', 'stroke', 'strategi', 'plc', 'jame', 'tehran', 'embassi', 'christma', 'auction', 'vladimir', 'determin', 'currenc', 'bit', 'treasuri', 'solut', 'mid', 'boss', 'auto', 'taiwan', 'blame', 'sharp', 'patriot', 'mar', 'flood', 'bn', 'yen', 'shoot', 'gather', 'domest', 'worst', 'trophi', 'separ', 'tradit', 'trader', 'mart', 'collect', 'wal', 'sanction', 'recov', 'meter', 'warm', 'halt', 'date', 'slip', 'richard', 'profession', 'indonesia', 'experi', 'earthquak', 'common', 'uranium', 'nokia', 'el', 'diseas', 'convent', 'michigan', 'licens', 'titan', 'qaeda', 'colin', 'cap', 'washingtonpost', 'specul', 'seriou', 'origin', 'microsystem', 'knee', 'impact', 'guilti', 'comment', 'bird', 'atom', 'amd', 'oppon', 'ohio', 'j', 'civilian', 'voic', 'turkey', 'recoveri', 'plead', 'pakistani', 'zone', 'paid', 'telecommun', 'signific', 'nextel', 'ford', 'daili', 'matter', 'mac', 'baltimor', 'addit', 'shock', 'mount', 'lot', 'edit', 'arizona', 'rich', 'resolv', 'putin', 'monitor', 'fiscal', 'budget', 'legisl', 'class', 'veteran', 'tomorrow', 'sure', 'pledg', 'page', 'warner', 'trip', 'surgeri', 'properti', 'histor', 'pm', 'foot', 'vow', 'rel', 'progress', 'district', 'attend', 'wild', 'philippin', 'june', 'enrich', 'copi', 'pacif', 'happen', 'easi', 'sadr', 'republ', 'refuge', 'plu', 'address', 'stewart', 'patient', 'colorado', 'telecom', 'sweep', 'raid', 'deadli', 'conduct', 'chart', 'kashmir', 'diego', 'core', 'twice', 'renew', 'packard', 'montreal', 'stem', 'robert', 'hewlett', 'throw', 'fla', 'thailand', 'prompt', 'opportun', 'noth', 'instal', 'formal', 'cooper', 'anim', 'allianc', 'alli', 'watchdog', 'seiz', 'prioriti', 'martin', 'itun', 'draft', 'sea', 'disrupt', 'counti', 'convict', 'virtual', 'surviv', 'enabl', 'collaps', 'websit', 'tough', 'sixth', 'rooki', 'prospect', 'previous', 'fill', 'demonstr', 'pair', 'nigeria', 'mix', 'l', 'karzai', 'treatment', 'su', 'relief', 'dismiss', 'defenc', 'broker', 'welcom', 'speci', 'realli', 'par', 'alan', 'vulner', 'payment', 'msn', 'hamid', 'familiar', 'done', 'spark', 'secret', 'materi', 'jakarta', 'grew', 'andi', 'shift', 'seventh', 'r', 'novel', 'dolphin', 'rare', 'magazin', 'handheld', 'grant', 'english', 'client', 'commission', 'present', 'portabl', 'nhl', 'founder', 'describ', 'alex', 'sound', 'shiit', 'saddam', 'expo', 'expens', 'commerc', 'boy', 'bar', 'anaheim', 'twin', 'resolut', 'non', 'hot', 'flat', 'egypt', 'deadlin', 'crew', 'sen', 'friend', 'appoint', 'adopt', 'toll', 'strength', 'seat', 'saudi', 'journalist', 'utah', 'irish', 'cancer', 'brother', 'factori', 'upset', 'quickli', 'ninth', 'mutual', 'impos', 'astronaut', 'affect', 'worm', 'tackl', 'liverpool', 'copyright', 'truck', 'super', 'sudanes', 'shut', 'moment', 'climat', 'brussel', 'transport', 'son', 'often', 'expans', 'entir', 'ballot', 'powel', 'patch', 'jeff', 'focus', 'eighth', 'competitor', 'answer', 'output', 'orbit', 'love', 'idea', 'channel', 'wake', 'spread', 'slam', 'restructur', 'chri', 'beach', 'handset', 'firefox', 'dramat', 'denver', 'compar', 'carlo', 'upcom', 'rather', 'indianapoli', 'hunt', 'gulf', 'barri', 'ag', 'mind', 'knock', 'hussein', 'flaw', 'fastest', 'contain', 'coalit', 'catch', 'traffic', 'resourc', 'plot', 'inventori', 'indonesian', 'crucial', 'clinch', 'wire', 'speech', 'reportedli', 'journal', 'greek', 'flu', 'choic', 'certain', 'blood', 'begun', 'wi', 'chase', 'bought', 'allegedli', 'ticker', 'sought', 'ring', 'regular', 'fighter', 'cub', 'vioxx', 'princ', 'partnership', 'kevin', 'identifi', 'atlant', 'unlik', 'ranger', 'minor', 'individu', 'georgia', 'establish', 'tennesse', 'tampa', 'pre', 'enron', 'disast', 'charl', 'remot', 'radic', 'nintendo', 'alway', 'ukrain', 'specif', 'maintain', 'cincinnati', 'wale', 'via', 'semifin', 'select', 'os', 'info', 'dream', 'definit', 'strengthen', 'sir', 'scale', 'mozilla', 'loan', 'islamabad', 'faster', 'craig', 'cancel', 'nascar', 'motion', 'lack', 'hama', 'forest', 'exist', 'devast', 'deputi', 'democraci', 'summit', 'strain', 'shuttl', 'militia', 'ill', 'hardwar', 'ebay', 'donald', 'advantag', 'technic', 'newsfactor', 'nationwid', 'capac', 'brave', 'touch', 'helicopt', 'governor', 'facil', 'supercomput', 'stun', 'micro', 'merck', 'flash', 'bell', 'attent', 'territori', 'safe', 'mountain', 'intend', 'extra', 'dame', 'cool', 'tight', 'subscrib', 'programm', 'opec', 'hat', 'wrong', 'teammat', 'sky', 'notr', 'newli', 'elimin', 'educ', 'dodger', 'centr', 'cabinet', 'similar', 'lawmak', 'indiana', 'inch', 'hp', 'girl', 'antitrust', 'writer', 'joe', 'driven', 'deep', 'switch', 'smaller', 'pt', 'ivori', 'celtic', 'villag', 'stronger', 'steel', 'smith', 'premiership', 'musharraf', 'grab', 'tini', 'preliminari', 'pharmaceut', 'overnight', 'ottawa', 'instant', 'br', 'berlin', 'amount', 'van', 'oklahoma', 'mp', 'jacqu', 'increasingli', 'databas', 'spywar', 'overal', 'nl', 'java', 'gone', 'fact', 'environ', 'conserv', 'broken', 'wife', 'style', 'situat', 'organis', 'desert', 'gunmen', 'failur', 'extens', 'weigh', 'treat', 'squar', 'seoul', 'popul', 'leg', 'hall', 'gear', 'era', 'dope', 'wonder', 'unless', 'observ', 'milan', 'jersey', 'cast', 'wayn', 'port', 'mr', 'haiti', 'fit', 'falluja', 'coupl', 'bomber', 'abandon', 'unbeaten', 'speak', 'oust', 'kind', 'drove', 'brian', 'sym', 'spur', 'solid', 'slide', 'qtype', 'qcat', 'infotyp', 'holi', 'burn', 'airbu', 'wicket', 'soft', 'sex', 'semi', 'note', 'gate', 'frank', 'enhanc', 'smart', 'pedro', 'gari', 'egyptian', 'martinez', 'environment', 'cnn', 'abil', 'surfac', 'river', 'lay', 'greater', 'franchis', 'favor', 'crack', 'contest', 'ticket', 'teenag', 'scotland', 'piraci', 'peter', 'perhap', 'perfect', 'overtim', 'difficult', 'construct', 'bryant', 'allawi', 'walt', 'virgin', 'vienna', 'slash', 'pervez', 'larri', 'jay', 'invit', 'discount', 'annan', 'nikkei', 'infring', 'handl', 'everyth', 'email', 'drink', 'achiev', 'violent', 'surround', 'ron', 'penalti', 'pain', 'newcastl', 'mysteri', 'fi', 'redskin', 'pga', 'lake', 'jr', 'goe', 'destroy', 'spring', 'restor', 'letter', 'either', 'contribut', 'behead', 'verizon', 'self', 'rescu', 'recommend', 'marathon', 'graphic', 'trust', 'scientif', 'saturn', 'ongo', 'offset', 'massachusett', 'jan', 'gun', 'fee', 'ceremoni', 'task', 'social', 'protocol', 'paper', 'lion', 'kofi', 'bin', 'beta', 'attract', 'theft', 'lock', 'languag', 'juri', 'ident', 'freed', 'cold', 'bu', 'bigley', 'april', 'thoma', 'swap', 'shi', 'shell', 'separatist', 'scott', 'rover', 'leadership', 'corrupt', 'combat', 'columbia', 'taliban', 'particip', 'lie', 'highli', 'fish', 'ensur', 'encourag', 'auburn', 'throughout', 'respect', 'resort', 'plung', 'lineup', 'disc', 'cuba', 'bob', 'blog', 'beyond', 'bat', 'amazon', 'util', 'sri', 'regist', 'piec', 'onto', 'msft', 'locat', 'labour', 'intens', 'harri', 'disclos', 'assembl', 'apart', 'altern', 'ali', 'type', 'swiss', 'suspens', 'revis', 'equiti', 'distanc', 'born', 'boom', 'aol', 'aggress', 'sexual', 'laden', 'justin', 'hacker', 'door', 'batter', 'vijay', 'usual', 'tap', 'sit', 'resist', 'pirat', 'owen', 'jewish', 'impress', 'h', 'edward', 'cingular', 'assassin', 'trigger', 'reviv', 'caught', 'bangladesh', 'advis', 'virus', 'roddick', 'revers', 'postseason', 'infrastructur', 'fellow', 'consol', 'typhoon', 'shipment', 'pacer', 'notebook', 'intent', 'transfer', 'pose', 'ny', 'marsh', 'howev', 'foundat', 'erupt', 'bobbi', 'adam', 'zimbabw', 'usa', 'trail', 'toshiba', 'stretch', 'sidelin', 'robot', 'postpon', 'orlando', 'miner', 'lee', 'heard', 'explain', 'tree', 'samsung', 'laboratori', 'jim', 'jack', 'extrem', 'citizen', 'shrine', 'martha', 'iranian', 'escap', 'embattl', 'cloth', 'bolster', 'uefa', 'toy', 'southeast', 'reflect', 'raven', 'hike', 'fanni', 'convinc', 'circuit', 'brazilian', 'bottom', 'au', 'anyon', 'tent', 'supplier', 'steadi', 'retain', 'movement', 'morgan', 'mae', 'implement', 'heavyweight', 'fought', 'fair', 'drew', 'deleg', 'conclud', 'communist', 'anyth', 'succeed', 'matt', 'headquart', 'guerrilla', 'greenspan', 'examin', 'ex', 'dual', 'chemic', 'torn', 'squad', 'solar', 'rememb', 'peacekeep', 'orlean', 'oppos', 'monetari', 'ice', 'gordon', 'enjoy', 'compon', 'cassini', 'casino', 'arthriti', 'art', 'va', 'sunni', 'respond', 'pipelin', 'ocean', 'hewitt', 'friendli', 'barcelona', 'argentina', 'anniversari', 'kidnapp', 'ken', 'jean', 'forum', 'band', 'activist', 'tabl', 'scene', 'preseason', 'liber', 'favorit', 'child', 'brokerag', 'bargain', 'bare', 'strateg', 'statu', 'pop', 'pois', 'infect', 'enforc', 'andr', 'vs', 'subsidiari', 'subject', 'slump', 'shoulder', 'sbc', 'ride', 'multi', 'everyon', 'detect', 'beckham', 'argu', 'antonio', 'affair', 'trend', 'syria', 'starter', 'politician', 'chechen', 'cbc', 'spirit', 'regard', 'librari', 'label', 'ii', 'crown', 'complaint', 'turkish', 'stronghold', 'sometim', 'reliev', 'philip', 'obtain', 'netherland', 'miller', 'landmark', 'guy', 'freez', 'bbc', 'astronom', 'arena', 'andrew', 'wage', 'steroid', 'rome', 'relationship', 'qualiti', 'packer', 'mayor', 'lewi', 'kobe', 'gymnast', 'bridg', 'wrap', 'tear', 'incid', 'constitut', 'automak', 'tank', 'steeler', 'rooney', 'jackson', 'father', 'easier', 'nigerian', 'maria', 'malaysia', 'lowest', 'knew', 'greatest', 'function', 'deliveri', 'bitter', 'tourist', 'sustain', 'snap', 'mistak', 'guid', 'colt', 'ca', 'buyer', 'aliv', 'wenger', 'tripl', 'silicon', 'outsourc', 'osama', 'margin', 'especi', 'collabor', 'asid', 'vaccin', 'recruit', 'northeast', 'lanka', 'invas', 'coup', 'compens', 'carter', 'cannot', 'brain', 'abduct', 'unpreced', 'stephen', 'spi', 'sight', 'rig', 'fierc', 'weaker', 'sponsor', 'repeat', 'opinion', 'narrow', 'mosqu', 'indi', 'highlight', 'excit', 'complex', 'wear', 'vega', 'successor', 'shopper', 'normal', 'jaguar', 'hassan', 'er', 'dump', 'discoveri', 'broad', 'batteri', 'appli', 'shape', 'schill', 'qaida', 'pioneer', 'laptop', 'famou', 'curb', 'comeback', 'sentiment', 'presenc', 'piston', 'petroleum', 'lleyton', 'larger', 'flow', 'convoy', 'bigger', 'bankrupt', 'spammer', 'remark', 'navi', 'mclennan', 'ferguson', 'contact', 'consult', 'caribbean', 'ben', 'arabia', 'anthoni', 'ankl', 'acknowledg', 'pursu', 'photograph', 'phoenix', 'object', 'mayb', 'maryland', 'liquid', 'fashion', 'entri', 'editor', 'blockbust', 'vietnam', 'tumbl', 'sweden', 'shanghai', 'sack', 'regulatori', 'nobel', 'multipl', 'hors', 'espn', 'kenneth', 'felt', 'fed', 'dark', 'citigroup', 'church', 'brief', 'adob', 'understand', 'showdown', 'optim', 'nortel', 'jeann', 'golden', 'frustrat', 'feet', 'clean', 'austria', 'actual', 'telescop', 'restrict', 'rape', 'overhaul', 'notic', 'k', 'jordan', 'ip', 'homeland', 'evacu', 'creation', 'contend', 'charlott', 'capsul', 'bull', 'balanc', 'accid', 'acceler', 'zarqawi', 'trap', 'margaret', 'manmohan', 'estat', 'disk', 'dick', 'crush', 'clinic', 'briton', 'amsterdam', 'adrian', 'wing', 'volum', 'valley', 'sear', 'roundup', 'pole', 'playstat', 'oversea', 'lab', 'innov', 'cowboy', 'congo', 'charley', 'carl', 'bet', 'unemploy', 'string', 'seal', 'reader', 'palm', 'orang', 'happi', 'gap', 'flag', 'exclus', 'coca', 'blew', 'allen', 'aboard', 'split', 'quarterfin', 'illinoi', 'hamm', 'gb', 'flagship', 'equal', 'brawl', 'beslan', 'will', 'vodafon', 'tropic', 'stern', 'snow', 'shown', 'quick', 'hang', 'gasolin', 'desper', 'curt', 'birdi', 'unexpect', 'tribun', 'religi', 'prais', 'mother', 'mostli', 'modern', 'midfield', 'influenc', 'inaugur', 'henri', 'headlin', 'exhibit', 'contractor', 'aviat', 'sluggish', 'silver', 'restaur', 'lebanon', 'divid', 'chile', 'unexpectedli', 'true', 'spitzer', 'plenti', 'palac']\n"
     ]
    }
   ],
   "source": [
    "# this will create a vocabulary of the top 2500 words and then convert the text to a sequence of numbers\n",
    "vocab_size = 2500 # how many of the most frequent words to keep\n",
    "sequence_length = 30 # how many words we use to represent a description\n",
    "vectorizer = TextVectorization(max_tokens=vocab_size, output_sequence_length=sequence_length)\n",
    "# fit the vectorizer on the training data (find the most common words and assign values to them)\n",
    "vectorizer.adapt(stemmed_train_data_list)\n",
    "# show the selected words\n",
    "print(vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96000, 30)\n"
     ]
    }
   ],
   "source": [
    "# vectorize the training data (replace words by their associated values)\n",
    "train_data_vectorized = vectorizer(stemmed_train_data_list)\n",
    "# vectorize the validation data\n",
    "validation_data_vectorized = vectorizer(stemmed_validation_data_list)\n",
    "# vectorize the test data\n",
    "test_data_vectorized = vectorizer(stemmed_test_data_list)\n",
    "# this shape shows that we have our 96000 training examples, each as a vector of 30 integers\n",
    "print(train_data_vectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 289  980  353 1196  939   32 2234  899  177  564   31  289  647 1222\n",
      "   56  715  241    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0], shape=(30,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# see how a vectorized news description looks like\n",
    "print(train_data_vectorized[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then build a RNN.\n",
    "\n",
    "We use an *Embedding layer* to convert the integer sequences to embeddings. You can read about how this works [here](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding).\n",
    "\n",
    "The Bidirectional layer takes the input and passes it forwards and backwards through the LSTM (Long-Short Term Memory) layer. It allows the network to learn the context of the sentence in both directions, so information from both previous and following words is taken into account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          80000     \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 64)                16640     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 96900 (378.52 KB)\n",
      "Trainable params: 96900 (378.52 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "750/750 [==============================] - 12s 13ms/step - loss: 0.4569 - accuracy: 0.8381 - val_loss: 0.3326 - val_accuracy: 0.8864\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 10s 13ms/step - loss: 0.3155 - accuracy: 0.8926 - val_loss: 0.3281 - val_accuracy: 0.8881\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.2979 - accuracy: 0.8970 - val_loss: 0.3250 - val_accuracy: 0.8881\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.2867 - accuracy: 0.9006 - val_loss: 0.3207 - val_accuracy: 0.8886\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.2760 - accuracy: 0.9041 - val_loss: 0.3179 - val_accuracy: 0.8903\n",
      "238/238 [==============================] - 1s 3ms/step\n",
      "Test Set Accuracy:  0.8860526315789473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# fit the model\n",
    "model.fit(\n",
    "    train_data_vectorized,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    validation_data=(validation_data_vectorized, validation_labels),\n",
    ")\n",
    "\n",
    "# predict the labels on the test data\n",
    "rnn_predictions = model.predict(test_data_vectorized)\n",
    "# since predictions are one-hot encoded, we convert them to an int label taking the output with higher value\n",
    "rnn_predictions = np.argmax(rnn_predictions, axis=1)\n",
    "\n",
    "# calculate the accuracy score\n",
    "accuracy = accuracy_score(test_labels_list, rnn_predictions)\n",
    "print(\"Test Set Accuracy: \", accuracy)\n",
    "# create a confusion matrix\n",
    "cm = confusion_matrix(test_labels_list, rnn_predictions)\n",
    "# plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=label_names, yticklabels=label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy for RNN model: 88.61%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test set accuracy for RNN model: {accuracy_score(test_labels_list, rnn_predictions)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO 3: Creating Example Predictions\n",
    "Test the model. Create some fresh sample news (copy them from a news site like BBC) then see if the model can predict the correct labels. Use one example per class.\n",
    "\n",
    "Also, find one example that gets misclassified and briefly discuss here why it might happen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "NN classifier prediction:  World News\n",
      "NN classifier prediction:  Sports News\n",
      "NN classifier prediction:  Business News\n",
      "NN classifier prediction:  Sci/Tech News\n",
      "NN classifier prediction:  Business News\n"
     ]
    }
   ],
   "source": [
    "sample_news = list()\n",
    "# TODO 3: create some fresh sample news (copy them from a news site like BBC) then see if the model can predict the correct labels\n",
    "# Use one example per class\n",
    "sample_news.append(\"Ukraine and Russia have exchanged hundreds of prisoners of war, in what is being described by officials in Kyiv as the biggest swap of the war.\")\n",
    "sample_news.append(\"Rory McIlroy says he would be open to play in a tournament backed by LIV Golf if the controversial tour became more like cricket's Indian Premier League.\")\n",
    "sample_news.append(\"Bosses of the biggest firms will earn more than the typical worker by Thursday lunchtime, research claims.\")\n",
    "sample_news.append(\"The company which became well known for its idea of shooting people hundreds of miles an hour through a vacuum has shut down.\")\n",
    "# Also, find one example that gets misclassified and discuss why it might happen in the markdown above.\n",
    "sample_news.append(\"SpaceX has been accused of unlawfully firing eight workers who were critical of its multi-billionaire chief executive Elon Musk.\")\n",
    "\n",
    "# preprocess the sample news\n",
    "sample_news = [preprocess_text(i) for i in sample_news]\n",
    "sample_news = remove_stopwords(sample_news)\n",
    "\n",
    "# If you added stemming/lemmatization, do it on sample_news as well\n",
    "stemmed_sample_news = [perform_stemming(text) for text in sample_news]\n",
    "\n",
    "# vectorize the sample news\n",
    "sample_news_vectorized = vectorizer(stemmed_sample_news)\n",
    "\n",
    "# predict using the neural network\n",
    "prediction = model.predict(sample_news_vectorized)\n",
    "prediction = np.argmax(prediction, axis=1)\n",
    "for i in prediction:\n",
    "     print(\"NN classifier prediction: \", label_names[prediction[i]], \"News\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sport's News - https://www.bbc.com/sport/golf/67870607\n",
    "\n",
    "Tech News- https://www.bbc.com/news/technology-67801235\n",
    "\n",
    "Misclassified News- https://www.bbc.com/news/business-67878940\n",
    "\n",
    "World News- https://www.bbc.com/news/world-europe-67872417\n",
    "\n",
    "Business News- https://www.bbc.com/news/business-67877235\n",
    "\n",
    "\n",
    "The missclassified news is misclassified because it is both considered Business news and comes from the tech sphere. The misrepresentation as Sci/Tech news may occur if the emphasis is exclusively on SpaceX's technological innovations or advancements in space exploration, ignoring the article's core theme of labor disputes and legal concerns. While there is mention of SpaceX's engagement in space-related activities, the main narrative is around internal business concerns, therefore \"Business\" is a more appropriate category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 4: Create a new model\n",
    "Try to improve the RNN model, of implement a CNN (with 1D convolution layers), that beats the baseline RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 30, 128)           320000    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 26, 128)           82048     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 5, 128)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1, 128)            82048     \n",
      "                                                                 \n",
      " global_max_pooling1d (Glob  (None, 128)               0         \n",
      " alMaxPooling1D)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 492612 (1.88 MB)\n",
      "Trainable params: 492612 (1.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "750/750 [==============================] - 12s 15ms/step - loss: 0.4739 - accuracy: 0.8259 - val_loss: 0.3363 - val_accuracy: 0.8839\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.3166 - accuracy: 0.8942 - val_loss: 0.3238 - val_accuracy: 0.8880\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 11s 15ms/step - loss: 0.2688 - accuracy: 0.9093 - val_loss: 0.3253 - val_accuracy: 0.8884\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.2116 - accuracy: 0.9273 - val_loss: 0.3618 - val_accuracy: 0.8843\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 11s 14ms/step - loss: 0.1553 - accuracy: 0.9443 - val_loss: 0.4057 - val_accuracy: 0.8827\n",
      "Test set accuracy for CNN model: 88.22%\n"
     ]
    }
   ],
   "source": [
    "# TODO 4: YOUR CODE HERE\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dropout\n",
    "\n",
    "# Define the CNN model\n",
    "cnn_model = Sequential()\n",
    "\n",
    "# Add an Embedding layer\n",
    "cnn_model.add(Embedding(vocab_size, 128, input_length=sequence_length))\n",
    "\n",
    "# Add Convolutional layers\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(5))\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# Add Dropout for regularization\n",
    "cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Add a Dense layer for classification\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dense(4, activation='softmax'))  # 4 classes \n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Display model summary\n",
    "cnn_model.summary()\n",
    "\n",
    "# Train the CNN model\n",
    "cnn_model.fit(train_data_vectorized, train_labels,\n",
    "              epochs=5,\n",
    "              batch_size=128,\n",
    "              validation_data=(validation_data_vectorized, validation_labels))\n",
    "\n",
    "# Evaluate the CNN model on the test set\n",
    "cnn_scores = cnn_model.evaluate(test_data_vectorized, test_labels, verbose=0)\n",
    "print(f\"Test set accuracy for CNN model: {cnn_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 66ms/step\n",
      "CNN classifier prediction:  World News\n",
      "CNN classifier prediction:  Sports News\n",
      "CNN classifier prediction:  Business News\n",
      "CNN classifier prediction:  Sci/Tech News\n",
      "CNN classifier prediction:  Business News\n"
     ]
    }
   ],
   "source": [
    "# Test the Model\n",
    "prediction2 = cnn_model.predict(sample_news_vectorized)\n",
    "prediction2 = np.argmax(prediction2, axis=1)\n",
    "for i in prediction2:\n",
    "     print(\"CNN classifier prediction: \", label_names[prediction2[i]], \"News\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 48s 61ms/step - loss: 0.4503 - accuracy: 0.8360 - val_loss: 0.3460 - val_accuracy: 0.8831\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 46s 61ms/step - loss: 0.3348 - accuracy: 0.8897 - val_loss: 0.3362 - val_accuracy: 0.8853\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 47s 63ms/step - loss: 0.3173 - accuracy: 0.8944 - val_loss: 0.3274 - val_accuracy: 0.8862\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.2980 - accuracy: 0.8994 - val_loss: 0.3236 - val_accuracy: 0.8867\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 50s 67ms/step - loss: 0.2815 - accuracy: 0.9038 - val_loss: 0.3297 - val_accuracy: 0.8844\n",
      "Test set accuracy for Improved RNN model: 88.22%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import LSTM, Dropout\n",
    "\n",
    "# Define an Improved RNN model\n",
    "improved_rnn_model = Sequential()\n",
    "\n",
    "# Add an Embedding layer\n",
    "improved_rnn_model.add(Embedding(vocab_size, 128, input_length=sequence_length))\n",
    "\n",
    "# Add LSTM layers with increased complexity\n",
    "improved_rnn_model.add(LSTM(128, return_sequences=True))\n",
    "improved_rnn_model.add(Dropout(0.3))\n",
    "improved_rnn_model.add(LSTM(64))\n",
    "improved_rnn_model.add(Dropout(0.3))\n",
    "\n",
    "# Add Dense layers for classification\n",
    "improved_rnn_model.add(Dense(64, activation='relu'))\n",
    "improved_rnn_model.add(Dense(4, activation='softmax'))  # 4 classes \n",
    "\n",
    "# Compile the improved RNN model\n",
    "improved_rnn_model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Train the improved RNN model\n",
    "improved_rnn_model.fit(train_data_vectorized, train_labels,\n",
    "                       epochs=5,\n",
    "                       batch_size=128,\n",
    "                       validation_data=(validation_data_vectorized, validation_labels))\n",
    "\n",
    "# Evaluate the improved RNN model on the test set\n",
    "improved_rnn_scores = improved_rnn_model.evaluate(test_data_vectorized, test_labels, verbose=0)\n",
    "print(f\"Test set accuracy for Improved RNN model: {improved_rnn_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 564ms/step\n",
      "Improved RNN classifier prediction:  World News\n",
      "Improved RNN classifier prediction:  Sports News\n",
      "Improved RNN classifier prediction:  Business News\n",
      "Improved RNN classifier prediction:  Sci/Tech News\n",
      "Improved RNN classifier prediction:  World News\n"
     ]
    }
   ],
   "source": [
    "# Predict using model\n",
    "prediction1 = improved_rnn_model.predict(sample_news_vectorized)\n",
    "prediction1 = np.argmax(prediction1, axis=1)\n",
    "for i in prediction1:\n",
    "     print(\"Improved RNN classifier prediction: \", label_names[prediction1[i]], \"News\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 13s 16ms/step - loss: 0.4693 - accuracy: 0.8296 - val_loss: 0.3336 - val_accuracy: 0.8856\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3139 - accuracy: 0.8945 - val_loss: 0.3229 - val_accuracy: 0.8874\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2635 - accuracy: 0.9105 - val_loss: 0.3214 - val_accuracy: 0.8901\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2048 - accuracy: 0.9291 - val_loss: 0.3557 - val_accuracy: 0.8840\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1494 - accuracy: 0.9472 - val_loss: 0.4006 - val_accuracy: 0.8825\n",
      "Test set accuracy for Improved CNN model: 87.39%\n"
     ]
    }
   ],
   "source": [
    "# Define an Improved CNN model\n",
    "improved_cnn_model = Sequential()\n",
    "\n",
    "# Add an Embedding layer\n",
    "improved_cnn_model.add(Embedding(vocab_size, 128, input_length=sequence_length))\n",
    "\n",
    "# Add Convolutional layers with increased complexity\n",
    "improved_cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "improved_cnn_model.add(MaxPooling1D(5))\n",
    "improved_cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "improved_cnn_model.add(GlobalMaxPooling1D())\n",
    "improved_cnn_model.add(Dropout(0.5))\n",
    "\n",
    "# Add Dense layers for classification\n",
    "improved_cnn_model.add(Dense(64, activation='relu'))\n",
    "improved_cnn_model.add(Dense(4, activation='softmax'))  # 4 classes \n",
    "\n",
    "# Compile the improved CNN model\n",
    "improved_cnn_model.compile(loss='categorical_crossentropy',\n",
    "                           optimizer='adam',\n",
    "                           metrics=['accuracy'])\n",
    "\n",
    "# Train the improved CNN model\n",
    "improved_cnn_model.fit(train_data_vectorized, train_labels,\n",
    "                       epochs=5,\n",
    "                       batch_size=128,\n",
    "                       validation_data=(validation_data_vectorized, validation_labels))\n",
    "\n",
    "# Evaluate the improved CNN model on the test set\n",
    "improved_cnn_scores = improved_cnn_model.evaluate(test_data_vectorized, test_labels, verbose=0)\n",
    "print(f\"Test set accuracy for Improved CNN model: {improved_cnn_scores[1]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 64ms/step\n",
      "Improved CNN classifier prediction:  World News\n",
      "Improved CNN classifier prediction:  Sports News\n",
      "Improved CNN classifier prediction:  Business News\n",
      "Improved CNN classifier prediction:  Sci/Tech News\n",
      "Improved CNN classifier prediction:  Business News\n"
     ]
    }
   ],
   "source": [
    "# Predict using model\n",
    "prediction3 = improved_cnn_model.predict(sample_news_vectorized)\n",
    "prediction3 = np.argmax(prediction3, axis=1)\n",
    "for i in prediction3:\n",
    "     print(\"Improved CNN classifier prediction: \", label_names[prediction3[i]], \"News\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 30, 128)           320000    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 26, 64)            41024     \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPoolin  (None, 6, 64)             0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 2, 128)            41088     \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Gl  (None, 128)               0         \n",
      " obalMaxPooling1D)                                               \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 410628 (1.57 MB)\n",
      "Trainable params: 410628 (1.57 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "750/750 [==============================] - 9s 11ms/step - loss: 0.4896 - accuracy: 0.8267 - val_loss: 0.3383 - val_accuracy: 0.8845\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 8s 11ms/step - loss: 0.3325 - accuracy: 0.8924 - val_loss: 0.3254 - val_accuracy: 0.8862\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 9s 11ms/step - loss: 0.2826 - accuracy: 0.9075 - val_loss: 0.3334 - val_accuracy: 0.8862\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.2240 - accuracy: 0.9263 - val_loss: 0.3626 - val_accuracy: 0.8820\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 9s 12ms/step - loss: 0.1660 - accuracy: 0.9455 - val_loss: 0.4009 - val_accuracy: 0.8788\n",
      "WARNING:tensorflow:5 out of the last 243 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001CCAD752820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "238/238 [==============================] - 1s 2ms/step\n",
      "Test Set Accuracy (CNN Model): 87.84%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "\n",
    "# Create a new model using CNN architecture\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(vocab_size, 128, input_length=sequence_length))\n",
    "cnn_model.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=4))\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Display the model summary\n",
    "cnn_model.summary()\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "cnn_model.fit(\n",
    "    train_data_vectorized,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    validation_data=(validation_data_vectorized, validation_labels)\n",
    ")\n",
    "\n",
    "# Predict the labels on the test data\n",
    "cnn_predictions = cnn_model.predict(test_data_vectorized)\n",
    "cnn_predictions = np.argmax(cnn_predictions, axis=1)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "accuracy_cnn = accuracy_score(test_labels_list, cnn_predictions)\n",
    "print(\"Test Set Accuracy (CNN Model): {:.2f}%\".format(accuracy_cnn * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "750/750 [==============================] - 13s 16ms/step - loss: 0.5326 - accuracy: 0.8031 - val_loss: 0.3424 - val_accuracy: 0.8827\n",
      "Epoch 2/5\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3350 - accuracy: 0.8915 - val_loss: 0.3250 - val_accuracy: 0.8885\n",
      "Epoch 3/5\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3014 - accuracy: 0.9028 - val_loss: 0.3245 - val_accuracy: 0.8870\n",
      "Epoch 4/5\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2589 - accuracy: 0.9146 - val_loss: 0.3296 - val_accuracy: 0.8859\n",
      "Epoch 5/5\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2060 - accuracy: 0.9329 - val_loss: 0.3525 - val_accuracy: 0.8853\n",
      "238/238 [==============================] - 1s 2ms/step\n",
      "Test Set Accuracy (Modified CNN Model): 88.17%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "\n",
    "# Create a modified CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(vocab_size, 128, input_length=sequence_length))\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=4))\n",
    "cnn_model.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))  # Adding dropout for regularization\n",
    "cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0005)  # Adjust the learning rate\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Fit the modified model\n",
    "cnn_model.fit(\n",
    "    train_data_vectorized,\n",
    "    train_labels,\n",
    "    epochs=5,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    validation_data=(validation_data_vectorized, validation_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the modified CNN model\n",
    "cnn_predictions = cnn_model.predict(test_data_vectorized)\n",
    "cnn_predictions = np.argmax(cnn_predictions, axis=1)\n",
    "accuracy_cnn_modified = accuracy_score(test_labels_list, cnn_predictions)\n",
    "print(\"Test Set Accuracy (Modified CNN Model): {:.2f}%\".format(accuracy_cnn_modified * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "750/750 [==============================] - 13s 17ms/step - loss: 0.5473 - accuracy: 0.7949 - val_loss: 0.3429 - val_accuracy: 0.8845\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.3351 - accuracy: 0.8911 - val_loss: 0.3296 - val_accuracy: 0.8871\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2986 - accuracy: 0.9025 - val_loss: 0.3236 - val_accuracy: 0.8901\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2565 - accuracy: 0.9162 - val_loss: 0.3295 - val_accuracy: 0.8876\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.2012 - accuracy: 0.9351 - val_loss: 0.3619 - val_accuracy: 0.8827\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.1410 - accuracy: 0.9555 - val_loss: 0.4149 - val_accuracy: 0.8817\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.0961 - accuracy: 0.9693 - val_loss: 0.4695 - val_accuracy: 0.8763\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.0648 - accuracy: 0.9805 - val_loss: 0.5530 - val_accuracy: 0.8745\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.0497 - accuracy: 0.9863 - val_loss: 0.6571 - val_accuracy: 0.8706\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 12s 16ms/step - loss: 0.0422 - accuracy: 0.9886 - val_loss: 0.6852 - val_accuracy: 0.8717\n",
      "238/238 [==============================] - 1s 2ms/step\n",
      "Test Set Accuracy (Modified CNN Model): 87.05%\n"
     ]
    }
   ],
   "source": [
    "# Remodified the Model by increasing the Ephocs from 5 to 10\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout, SpatialDropout1D\n",
    "\n",
    "# Create a modified CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(vocab_size, 128, input_length=sequence_length))\n",
    "cnn_model.add(Conv1D(128, 5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=4))\n",
    "cnn_model.add(Conv1D(64, 5, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(64, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))  # Adding dropout for regularization\n",
    "cnn_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.0005)  # Adjust the learning rate\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Fit the modified model\n",
    "cnn_model.fit(\n",
    "    train_data_vectorized,\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    verbose=1,\n",
    "    validation_data=(validation_data_vectorized, validation_labels)\n",
    ")\n",
    "\n",
    "# Evaluate the modified CNN model\n",
    "cnn_predictions = cnn_model.predict(test_data_vectorized)\n",
    "cnn_predictions = np.argmax(cnn_predictions, axis=1)\n",
    "accuracy_cnn_modified = accuracy_score(test_labels_list, cnn_predictions)\n",
    "print(\"Test Set Accuracy (Modified CNN Model): {:.2f}%\".format(accuracy_cnn_modified * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following extensive work to enhance the baseline model, **the baseline model achieved the highest accuracy of 88.61% and accurately forecasted the sample news.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO  5\n",
    "\n",
    "**TODO 1** \n",
    "\n",
    "Removing URLs and Links from text. This step is important since URLs often do not provide useful information for text categorization and can introduce noise into the dataset.\n",
    "\n",
    "Removing News Agency Names. The method also removes individual news agency names such as \"Reuters\" and \"AFP\". This step is intended to reduce bias or overfitting caused by the presence of agency names in the text. It is critical when training the model on data when the agency name may be an influential component in categorization but is irrelevant in other circumstances.\n",
    "\n",
    "**TODO 2**\n",
    "\n",
    "Before deciding between lemminization and stemming, I decided to experiment with both approaches and assess their impact on the performance of my classification model. Both stemming and lemmatization aim to reduce words to their base or root form but use different approaches and have distinct characteristics, so I decided to experiment with both approaches and assess their impact on the performance of my classification model. Following that, I obtained the following result from the comparison:\n",
    "\n",
    "Stemmed Validation Accuracy: 0.8960416666666666667\n",
    "\n",
    "Accuracy of Lemmatized Validation: 0.8703333333333333\n",
    "\n",
    "Stemming outperformed lemmatization in terms of performance, thus I chose stemming.\n",
    "\n",
    "**TODO 3**\n",
    "\n",
    "It is critical to evaluate the model to ensure its dependability, generalizability, and efficacy in making accurate predictions on fresh, unseen data. We will be able to ensure the reliability of our model for real-world case scenarios if we use current news to evaluate it.\n",
    "\n",
    "**TODO 4**\n",
    "\n",
    "In practice, it is critical to experiment with various designs, closely monitor performance metrics (accuracy, etc), and confirm the model's performance on distinct test sets. This iterative method aids in understanding how architectural changes affect the model's behavior and performance on unknown data, allowing the best model architecture for the particular task to be chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources:\n",
    "\n",
    "- Implement a recurrent neural network : https://peterroelants.github.io/posts/rnn-implementation-part01/\n",
    "\n",
    "- Peforming Encoding: https://www.geeksforgeeks.org/feature-encoding-techniques-machine-learning/\n",
    "\n",
    "- Using Regular Expression: https://www.geeksforgeeks.org/regular-expression-python-examples/\n",
    "\n",
    "- Performing Stemming: https://www.geeksforgeeks.org/introduction-to-stemming/\n",
    "\n",
    "- Source for Sample News: https://www.bbc.com/\n",
    "\n",
    "- Implementing Text Vectorization: https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization\n",
    "\n",
    "- Implementing CNN: https://www.geeksforgeeks.org/introduction-convolution-neural-network/?ref=header_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "977335c72b126e3991b9de8b6fc74c7a8bf9097191ab51ecd2769bb8eacdf950"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
